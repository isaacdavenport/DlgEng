From the SBIR proposal for this project

Talking Toys Children Create Which Promote Emotional, Scientific, and Communication Learning
by Isaac Davenport PhD
  303.859.5773
  isaac@isaacdavenport.com 

Elevator Pitch
Toys2Life is creating an artificial intelligence enabled platform that allow dolls and action 
figures to talk to one another.  Children can control the conversation by moving dolls closer 
and farther from one another to select who talks to whom.  A low cost, Bluetooth Low Energy 
(BLE) based real time proximity matrix is used to track the dolls.  A tablet, laptop, or 
smartphone provides the intelligence and audio database.  

Educators and therapists will be the first customers, eventually tech forward parents and kids 
where the children have access to hand me down smart phones or tablets, and finally most kids 
as access to computational power trickles down to the younger children of lower middle class 
and even poorer families. 
 
The benefits to kids and hence society will be twofold:  the first is FUN; the second an outlet 
for creative, intrinsically-motivated learning.  These benefits come from Toys2Life’s innovation 
in artificial intelligence.  By working at a sentence level, rather than a word level, and using 
emotion and intent extraction and a probabilistically generated combinatoric dialog space.  
Significantly unique interactions can be had between characters with a much more limited supply of 
phrases.

Early play tests with the prototype have shown promise.  Even though kids may not know what the 
“Internet of Things” is, they enjoy playing on it.  Patents on the artificial intelligence (AI) 
and BLE innovations have been filed.  This far, children have showed great interest in creating 
their own characters where they can learn about the mechanics of language, the emotional content 
of language, and the process of programming.  

Minecraft, like Legos, tinker toys, and erector sets before, has shown that when kids are given a 
good platform to create learning can be fun (Junco 2014).  Toys2Life takes the concept of a child 
writing a story to the next level of creating a character, that can interact with other characters, 
both those provided by Toys2Life and those created by other children.  

Commercial Opportunity
Too many educational toys fall into the no man’s land between fun enough for playing and educational enough for learning.  Toys2Life is an infinite game where players adjust the rules to continue play as opposed to a finite game with winners and losers who are working toward an end goal like most modern video games (Carse 1987).  Toys2Life seeks to fulfill a long existing desire on the part of children to have their toys talk and to leverage that desire and magic to generate intrinsic motivation to learn (Dweck 1986)(Ryan 2000).
The promise of the Toys2Life platform is the experience of the movie “Toy Story” on a kid’s bedroom floor.  Before Toy Story, there was Pinocchio, and before that The Nutcracker.  Kids have dreamed of their toys coming to life and talking to one another for a very long time.  The desire and demand are there.  
This far proving of the commercial viability of the system has been limited to discussion of the system with educators such as Sylvia Meyers 4th grade teacher, Heidi Kessler middle school principal, Emily Davenport, middle school teacher librarian, and Jessica Wiggins play therapist as well as successful play testing with kids and discussions of commercial viability with industry veterans such as Justin Discoe and John Blakely.  The desire for talking toys is well known.  The commercial viability will come from the execution of the user experience.
The tech required to realize this vision is converging.  Low cost BLE silicon is here that can bring dozens of a child’s toys to life at a sub $15 retail price point through an ex-factory electronics cost under $2.50.  Combining this with the processing power available to kids through the proliferation of hand-me-down and kid oriented tablets, laptops, and smart phones that attach to the power of the cloud a new kind of talking toy is possible.  
Because the individual characters can be low cost, a “collect them all”, marketing approach can be used.  Kids can see what their characters will say to difference characters owned or created by their friends.  If a child owns the princess or infantryman character, they will be naturally curious to see not only what those two will say to each other, but to the cowboy character they want to purchase next.
This play pattern differs greatly from that used by what is currently described as the Toys2Life genre which is dominated by Skylanders, Disney Infinity and Playmation, Nintendo Amiibo, and Legos Dimensions (Wikipedia Toys to Life).  Aside from Playmation and Dimensions, there is no playing with the actual toy.  But even with Playmation and Dimensions the play is all contained on the screen and there is no facility for the child to create their own content.  Content creation is a part of some video games, namely Minecraft.  But these games are a minority and still focus entirely on the screen.  Toys2Life allows content creation using the child’s own words and voice.  In order to create, the child must learn about the underlying emotional content of what the created character is saying in order to align proper responses from other characters. Children can potentially use Youtube as a free form content creation and sharing platform.  But Youtube isn’t a great environment for kids, and younger children especially benefit from the structured creation environment provided by Toys2Life as well as the tactile element of play away from the screen. 
This new breed of talking toy requires a different kind of AI and a different kind of thinking than what is being developed now.  The failure of most educational and smart toys has been sewn by focus on the educational part or the smart part rather than the central part of what it means to be a toy.  FUN!  Imaginative play with action figures and dolls has been taking a back seat to the television watching experience and the video game experience.  Toys2Life aims to put the action figure and doll play experience back into center stage of childhood by making physical toys a platform for top notch content that rival the entertainment of television and video games.  If this is done in a way that leaves the platform open for kids to create their own content, there is a chance to make a primary play and entertainment activity a learning activity as opposed to the passive entertainment consumption of most television and video game “screen time”.
The pull string based Chatty Cathy dolls of the sixties have given way to toys including an audio chip that do the same dozen phrases digitally.  The latest crop of smart toys is attempting to talk and interact with the child directly.  Interacting directly with a child is a very difficult problem, due to issues of speech recognition with children, the limited emotional content of synthetic speech, the limited content available with voice actor speech, the AI required for unconstrained interaction and most difficult, the high expectation level children have of a digital toy that talks to the child about whatever topic the child may wish to talk about. 
In the excitement and continuing disappointment with toys that talk to children, such as Ubooley or “Hello Barbie”, the more tractable problem of creating AI that allows toys to talk to one another has been under-explored.  In the more constrained environment of toys that talk to one another, a much smaller collection of pre-recorded phrases can provide a large combinatorial set of interactions.  Using Toys2Life’s patent pending “dialog simulation” different levels of context can be used.  In a context free unscripted environment characters created without knowledge of one another can converse and interact.  
On the other end of the spectrum, fully scripted interactions can be woven together into a sort of “choose your own adventure” experience where the child not only uses the proximity control of the dolls or action figures to control who talks to whom, but makes decisions affecting the thread of the story through a branching narrative tree.  Users can start with the simple context free content generation and control their character as it interacts with other characters.  From there, they can move on to telling the story they want to tell with their character using single sided dialog as they identify the emotional triggers in their story that should elicit appropriate responses from the other side.  Finally users can dive deep and create their own branching dialog tree to create their own experience that sits between that of a movie, a video game, and doll / action figure play.
The market success of Toys2Life will eventually depend on engagement of “property owners”.  The ability to sell toys of any kind hinges on the Disney’s and Hasbro’s of the world allowing their beloved characters onto it.  Thus far, the toy industry has lacked opportunities for recurring revenue.  The Toys2Life platform is well positioned to generate recurring revenue from subscriptions allowing the toys to be “more alive” with regular automatic downloads of new phrases, adventures, and dialog models for purchased characters with active subscriptions.
One possible commercialization path for Toys2Life is purchase by a major property holder.  Prior to that Toys2Life will pursue current license holders.  Toy manufacturers the PI has worked with already have a customer base filled with property license holders who may be able to add speech to their products under existing licenses or re-negotiate their licenses.   Chinese toy manufacturers are also eager to develop IP of their own and are capable of manufacturing the radio hardware and selling it as a value add to their customer base.  It is possible the hardware, which is simple, could be released under an open hardware license, the firmware implementing the Toys2Life patent pending real time proximity matrix firmware could be licensed to various manufacturers, and the higher margin, back end web based subscription service and content authoring toolkit could be managed by Toys2Life.
In addition to the paths of working with smaller license holders or the primary property owners, it will likely make sense to do a small B2C step through a crowdfunding mechanism to fund beta testing on a larger scale than the Boulder playtesting cohort.  This early revenue should also help with access to Series A investment and debt financing.  An early investment or even partnership by an interested Chinese toy manufacturer is also a possibility.  Commercialization is a task to be taken on after the technological hurdles of Phase I are completed.
The primary risks to bringing the innovation of Toys2Life to market are in the technical tasks involved in making the system both very fun and highly educational and the finding distribution that allows us to compete against the Disneys and Nintendos of the marketplace.  For this reason it makes sense to focus on the education and therapy market first to establish ourselves while we look for the right partner to help us roll out a mass market version.  For mass market, Toys2Life can simplify marketing and distribution by offering the platform to property holders.  The property holders will then market to the end customers and do distribution.
Once enough play tests and development iterations have been completed, the first customers will be educators and therapists.  The larger market of parents and kids interested in educational toys will then be approached once the product has been vetted within the educational niche and a budget for mass marketing has been established.  Eventually our customers will be license holders of major toy properties such as Disney or Hasbro characters.  The market for licensed toys is in the tens of billions of dollars worldwide.  Plastic and plush toys tend to sell in the $8-$28 range.  So, a sub-three-dollar addition to a toy that allows it to actually talk to any other Toys2Life toy and go on adventures directed by the child is a huge value add over adding a dozen static phrases.  The toy industry is desperate for recurring revenue streams.  Toys2Life subscriptions for regular content updates will be a welcome business model.
Eventually a web back end will need to be developed.  This is not part of the MVP (minimum viable product) but will play a key role in making the platform attractive to “property holders”.

The Innovation
The innovation behind the Toys2Life system includes Bluetooth low energy (BLE) radio innovation, artificial intelligence (AI) innovation, and innovation in applying these technologies to education.  The radios give proximity of one toy to the others.  The proximity is controlled by the child.  The proximity matrix data stream is fed into the dialog engine.  The AI in the dialog engine chooses the characters to converse, based on proximity and history, then chooses the dialog model to converse through, finally the AI in the dialog engine chooses probabilistically the phrases that each character will say for the current dialog model.  This project has not been proposed to and granting agencies prior to this proposal.  There are two patents files on the AI and RSSI-BLE technology (Davenport 2016).
It is the tagging feature in the dialog engine that will allow children to learn about the emotional content of language.  Kids will study example phrases with tags like “Angry_Response”, “Disgusting_Statement”, or “Joyful_Response” to understand how to create their own “Angry_Response” that might follow an “Insult” or their own “Statement_Of_Regret” that might elicit a “Sympathy” or “Reassurance” response.
To create a character kids will learn about STEAM topics such as writing, and set theory as they determine which phrases can be “greetings”, “exclamations”, or both? They will learn about computational thinking using variables and probability as they create phrases to be picked by the probability engine based on their weighting selections for different tags.  They will also learn about grammar and syntax from an English perspective as they write substitutable phrases, and from a programming perspective as they use a template to create a traversable phrase tree to send their character on a scripted choose-your-own-adventure.
While the work of Nuance Inc. on Siri, Dragon and other products has been a great step forward in natural language where phonology and morphology are the drivers, the higher one goes into syntax and semantics the poorer the performance of AI.  Fortunately our performance goal is the entertainment of seven year olds, which is a much lower bar than the kind of accuracy the users of Siri or Dragon require.  This makes Toys2Life a great place to push the forefront of English language syntactical and especially semantic work.
To create content for the Toys2Life system, writers write dialog models that allow for various combinations of phrase types to be traded back and forth in small conversations.  Within the dialog engine the writers don't have to know one another or know about the other writer's characters to allow the characters to talk to one another.  Writers simply create phrases for their character that match some of the phrase types used in the dialog models.  
A voice actor, or child that owns a character, records the phrases for the character.  An end user purchases the character in the form of a radio with a unique identifier.  The user downloads the application to a PC, smartphone, or tablet computer.  The application uses a real time proximity map of the toys/characters purchased by the user.  The user may control which toy talk to which other toy by moving the toys farther or closer together as kids tend to do in a traditional doll based play pattern.
The primary use of the audio dialog engine is for toys that talk and interact with one another based on input from the user.  Eventually the dialog engine might be used to generate conversations between non-player characters in a video game environment.  This dialog engine is novel in that it provides thousands of possible unique dialogs between each pair of as many characters are created based on only a couple hundred recorded sentences/phrases per character.  Uniquely it also allows synthetic characters to interact with one another, even though they may have been written and recorded with no knowledge of one another.  The engine provides a framework for many independent contributors to generate characters who can all interact with one another in either a fully unscripted and context free style or in a fully scripted way if the characters were developed together or any place in between along the spectrum of unscripted to scripted.
The system allows for regular updates to dialog models and character phrase lists to keep the toys alive and saying new things over the life of the toy.  
Toys2Life leverages the power of ubiquitous, computers, laptops, tablets, and smart phones to provide a much richer experience at a significantly lower price using low cost radios.  
The toys can be dolls, action figures, figurines, plush toys, trucks, boats, cars, or trains.  Some of the toys may be stationary objects such as a doll house, school, police station, or castle.  Stationary toys may be included in the real time proximity map just to help the dialog engine sequence dialog models involving locations or they may also have a character and a voice associated with them.  The radios currently in use are CSR1010 low cost BLE radios including an integrated processor and memory for running firmware that generates custom advertising packets.  However, the Nordic nRF51 series ICs could also be used.
The “real time proximity map” is a data stream in the form of a matrix that is updated in real time to show the proximity of each toy to every other toy.  This is achieved using received signal strength indication (RSSI) from a Bluetooth low energy (BLE) radio in the toy.  A “dialog model” is a list of phrase types and character indexes such as Character1, Character2, and Character3 for mapping phrase types onto selected characters.  The dialog model can be context free, one sided, or fully scripted.  A “character” is essentially a collection of phrases and phrase type weightings.  The phrases are recorded by a voice actor or child.  A character also includes metadata such as character name, age, and gender.  The concept of a “phrase type” is a classification for a phrase such as greeting, request for sympathy, or give location.  Phrases will often have more than one type.
The dialog engine itself is in charge of selecting which characters are having a dialog, which dialog model is active and which phrases of a given type the characters will speak when the dialog model prescribes the speaking character to speak a particular phrase type.  The characters to be speaking will generally be selected by the two characters in closest proximity.  However, dialog models involving three or more characters may be implemented.  The dialog engine also monitors the proximity of the speaking dolls and interrupt the dialog model if the proximity of the dolls changes.
A dialog model is a sequence of phrase types.  A dialog is a sequence of spoken phrases by one or more characters which are selected according to a dialog model.  A phrase is a complete utterance by a character.  A phrase type is a classification of a phrase such that the phrase may be used in a dialog model.  Table 1 gives examples of possible phrase types.

exclamation	greeting	request for sympathy
a “yes” response	a “no” response	a yes no question
a surprising statement	a request for a joke	a request for sympathy
giving sympathy	telling a joke	a threat
a retreating statement	an advancing statement	an insult
request of advice	give advice	request a location
give a location	a ramble	request to catch up
a fearful response	an expression of disbelief	schoolboy-cowboy script1A
schoolboy-cowboy script1B 	schoolboy-cowboy script1C	schoolboy-cowboy script1D
express dismay	negative internal thought	positive internal thought
Table 1.  Sample phrase types

Within a character, a phrase will have a weighting factor for one or more phrase types.  There will likely be hundreds of phrase types and the list will grow over the life of the system.  A character from the dialog engine will be mapped onto a radio attached to a doll.  
A single phrase will often be classified under multiple phrase types using weighting factors.  For instance the cowboy character’s phrase “I’ll be” could be weighted a 1.5 as an exclamation, a 0.2 as a request for sympathy and 1.0 as an expression of disbelief.  The little boy character’s phrase “you have bad breath” could be a 1.2 weighting as an insult and a 0.8 weighting factor for a surprising statement and a 0.2 weighting factor as a retreating statement that could be used when the little boy is being moved away from another doll.
The dialog engine will select the dialog model after the speaking characters have been selected.  A dialog model will be selected from the feasible models.  Only dialog models where all the speaking characters have at least one phrase with non-zero weight for the phrase types required of the characters are feasible.  Dialog models that fit trends in the real time proximity map may be preferentially selected such as characters approaching, departing, being in vicinity of a another toy (mobile or stationary), or being thrown.  
As the dialog engine moves through a dialog model the dialog engine selects a characters phrases by weighted random selection.  For instance if the character to speak next is the cowboy and a request for sympathy phrase type is required, if the cowboy has three phrases with non-zero requestSympathy weightings: “I’ve been feeling a bit blue lately” = 4, “My Isabel says she won’t be coming back” = 6, and “I was thrown from my horse” = 2, the dialog engine would add the weights together to get twelve and generates a random number between zero and twelve.  If the number is less than four the cowboy would say “I’ve been feeling a big blue lately”.  If the number is between four and ten the cowboy would say “”My Isabel says she won’t be coming back” and if the number is between ten and twelve he would say “I was thrown from my horse”.
The system uses a novel “connectionless” model to generate the real time proximity map data stream.  Each toy periodically broadcasts an array of RSSI values into the local RF airspace in the form of an advertising packet.  This dynamic use, of the typically static, custom advertising header allows a much higher bandwidth since connections do not have to be continually made and broken.  Also, all listening toys can pick up the same advertising packet from a transmitting toy and glean an RSSI value.  In this way a single transmission is needed where a traditional connection based BLE scheme would require (n-1) times as many transmissions to establish the same information where n is the number of active toys.  
BLE advertisements are sent multiple times and the designer typically does not have control over this retransmission at the underlying BLE layer.  However, each repeated advertisement a radio sends is an opportunity for all the listening radios, including the one in the tablet to update its internal RSSI array.  Each row in the matrix is the array of “last seen RSSI” values from a given toy (or the radio in the tablet).  If a radio detects multiple duplicate RSSI values for a given radio, those could be filtered or averaged to give a more accurate RSSI proximity reading.  
Because RSSI is a relatively noisy signal, using the information from multiple readings is advantageous.  We also have the RSSI from the perspective of both toys to use in calculating proximities.  Toy2 has an RSSI at which he observed Toy3 recently transmit at.  Additionally Toy3 has an RSSI that he observed Toy2 transmit at.  
Aside from sensing which two characters are closest, the proximity data stream is used to detect when a character is in or near a play structure, such as a doll house or non-talking vehicle such as a toy car, if the car or house are also instrumented with radios.  The car or house may or may not be given character voices of their own.   
As additional phrase types are added, existing characters may be updated to participate in new dialog models that use a new phrase type if the character has existing phrases that could also be classified with a non-zero weighting for the new phrase type.
